# Taming Big Data with Apache Spark 4 and Python.pdf

## Certificate no: UC-6caea177-a20c-4576-8951-059e81364492
## Certificate url: ude.my/UC-6caea177-a20c-4576-8951-059e81364492

![Udemy - Taming Big Data with Apache Spark 4 and Python](https://github.com/user-attachments/assets/5011fc52-3619-494a-8140-34e41ddbb640)

---

### ğŸŒŸ **Learnings from â€œTaming Big Data with Apache Spark 4 and Pythonâ€**

* ğŸš€ **Spark 4 Features** â€“ Explore the latest capabilities of Spark 4.
* ğŸ“˜ **Introduction to Spark** â€“ Understanding Spark fundamentals.
* ğŸ”¹ **RDD (Resilient Distributed Dataset)** â€“ Core data structure for distributed computing.
* ğŸ—ï¸ **Spark Architecture** â€“ How Spark components interact.
* âš™ï¸ **Spark Context** â€“ Entry point for Spark functionality.
* ğŸ”„ **Transformations** â€“ Operations like `map()`, `filter()`, `flatMap()` that define new RDDs.
* ğŸ¯ **Actions** â€“ Operations like `collect()`, `count()` that trigger execution.
* â³ **Lazy Evaluation** â€“ Transformations are only computed when an action is called.
* ğŸ—ï¸ **Key-Value RDD Operations** â€“

  * `groupByKey()`
  * `reduceByKey()`
  * `sortByKey()`
  * `keys()` / `values()`
* ğŸ§© **flatMap()** â€“ Splitting elements into multiple outputs.
* ğŸ§® **Spark SQL** â€“ Query structured data using SQL syntax.
* ğŸ“Š **DataFrame Object** â€“ Optimized tabular data structure in Spark.
* ğŸ” **DataFrame Functions** â€“

  * `explode()`
  * `split()`
  * `lower()`
* ğŸ¼ **Pandas API on Spark** â€“ Seamless integration with pandas-like operations.

  * Convert **Pandas DF â†’ Spark DF**: `spark.createDataFrame(pandas_df)`
  * Convert **Spark DF â†’ Pandas DF**: `spark_df.toPandas()`
* ğŸ› ï¸ **User Defined Table Functions (UDTFs)** â€“ Custom functions for complex transformations.
* ğŸ–¥ï¸ **Spark UI** â€“ Visualize jobs, stages, and tasks.
* ğŸ¤– **Spark MLlib** â€“ Machine learning capabilities:

  * Regression: Linear, Logistic
  * Classification: SVM, Naive Bayes, Decision Trees
  * Clustering: KMeans
  * Dimensionality Reduction: PCA, SVD
  * Recommendations: ALS
* ğŸ“š **MLlib Library Imports** â€“

  ```python
  from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor
  ```
* ğŸŒŠ **Spark Streaming** â€“ Real-time data processing:

  ```python
  from pyspark.streaming import StreamingContext
  ```

---
